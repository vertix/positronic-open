import os
from pathlib import Path

from tqdm import tqdm
import hydra
import torch

from simulator.mujoco.environment import MujocoRenderer
from simulator.mujoco.sim import MujocoSimulator
from tools.dataset_dumper import SerialDumper


def process_episode(episode_path, cfg, output_dir):
    data = torch.load(episode_path)
    n_frames = len(data['image_timestamp'])

    loaders = hydra.utils.instantiate(cfg.hardware.mujoco_loaders)
    model_path = Path(episode_path).parent / data['relative_mujoco_model_path']
    simulator = MujocoSimulator.load_from_xml_path(model_path, loaders, simulation_rate=1 / cfg.hardware.mujoco.simulation_hz)
    renderer = MujocoRenderer(
        simulator,
        cfg.hardware.mujoco.camera_names,
        (cfg.hardware.mujoco.camera_width, cfg.hardware.mujoco.camera_height),
    )

    simulator.reset(data['keyframe'])
    renderer.initialize()
    dataset_writer = SerialDumper(output_dir, video_fps=cfg.hardware.mujoco.observation_hz)

    dataset_writer.start_episode()

    event_idx = 0
    tqdm_iter = tqdm(total=n_frames, desc=f"Processing {os.path.basename(episode_path)}")
    frames_rendered = 0

    while event_idx < n_frames:
        if data['image_timestamp'][event_idx] <= simulator.ts_ns:
            simulator.set_actuator_values(data['robot_joints'][event_idx])
            simulator.set_grip(data['target_grip'][event_idx])
            event_idx += 1
            tqdm_iter.update(1)

        tqdm_iter.set_postfix(sim_ts=simulator.ts_sec)
        simulator.step()

        if simulator.ts_sec >= frames_rendered / cfg.hardware.mujoco.observation_hz:
            frames_rendered += 1
            images = renderer.render_frames()

            actual_event_idx = max(0, event_idx - 1)

            dataset_writer.write(
                data = {
                    'actuator_values': simulator.actuator_values,
                    'grip': simulator.grip,
                    'robot_position_translation': simulator.robot_position.translation.copy(),
                    'robot_position_quaternion': simulator.robot_position.quaternion.copy(),
                    'ext_force_ee': simulator.ext_force_ee.copy(),
                    'ext_force_base': simulator.ext_force_base.copy(),
                    'robot_joints': simulator.joints.copy(),
                    'target_grip': data['target_grip'][actual_event_idx].clone(),
                    'target_robot_position_quaternion': data['target_robot_position_quaternion'][actual_event_idx].clone(),
                    'target_robot_position_translation': data['target_robot_position_translation'][actual_event_idx].clone(),
                    'image_timestamp': simulator.ts_sec,
                    'robot_timestamp': simulator.ts_sec,
                    'target_timestamp': simulator.ts_sec,
                },
                video_frames={
                    f'image.{mapped_name}': images[orig_name] for mapped_name, orig_name in cfg.image_name_mapping.items()
                },
            )


    tqdm_iter.close()
    dataset_writer.end_episode()


@hydra.main(version_base=None, config_path="../../configs", config_name="record_renderer")
def main(cfg):
    # Get all episode files from input directory
    input_files = [f for f in os.listdir(cfg.input_dir) if f.endswith('.pt')]
    input_files.sort()  # Process files in order

    print(f"Found {len(input_files)} episodes to process")

    for episode_file in tqdm(input_files, desc="Processing episodes"):
        episode_path = os.path.join(cfg.input_dir, episode_file)
        process_episode(episode_path, cfg, cfg.data_output_dir)


if __name__ == "__main__":
    main()
